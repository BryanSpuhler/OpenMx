Full Information Maximum Likelihood, Row Objective Specification
================================================================

*This document was authored by Michael D. Hunter, M.A.*

**This document is a draft.  Please excuse its disorderly state as I continue writing. -MDH**

This example will show how full information maximum likelihood can be implemented using a row-by-row evaluation of a likelihood function.  This example is in two parts.  The first part is a discussion of full information maximum likelihood.  The second part is an example implementation of full information maximum likelihood in a row-wise objective function that estimates a saturated model in two variables.  The second part refers to the following file:

*    http://openmx.psyc.virginia.edu/repoview/1/trunk/demo/FIMLRowObjectiveBivariateCorrelation.R

There is a parallel version of this example that uses the standard full information maximum likelihood implementation here:

*    http://openmx.psyc.virginia.edu/repoview/1/trunk/demo/BivariateCorrelation.R

The goal of the current document is twofold: to increase users' understanding of full information maximum likelihood, and to assist users in implementing their own row objective functions.

Full Information Maximum Likelihood
-----------------------------------

Full information maximum likelihood is almost universally abbreviated FIML, and it is often pronounced like "fimmle" if "fimmle" was an English word.  FIML is often the ideal tool to use when your data contains missing values because FIML uses the raw data as input and hence can use all the available information in the data.  This is opposed to other methods which use the observed covariance matrix which necessarily contains less information than the raw data.  An observed covariance matrix contains less information than the raw data because one data set will always produce the same observed covariance matrix, but one covariance matrix could be generated by many different raw data sets.

Although there is a loss of information between a raw data set and an observed covariance matrix, in structural equation modeling we are often only modeling the observed covariance matrix and the observed means.  Therefore, we are usually not concerned with the loss of information.  However, when some raw data is missing, the loss of information in computing the observed covariance matrix is a cause of concern.  The intelligent handling of missing data is a primary reason to use FIML over other estimation techniques.  The method by which FIML handles missing data involves filtering out missing values when they are present, and using only the data that are not missing in a given row.

If *X* is the entire data set then the minus two log likelihood of row *i* of the data is 

.. math::
    :nowrap:
    
    \begin{eqnarray}
    \mathcal{L}_i = 
    2 \ln(2 \pi) + \ln( | \Sigma_i | ) ) + (X_i - M_i) \Sigma_i^{-1}  (X_i - M_i)^{\sf T}
    \end{eqnarray}

where

* :math:`\ln()` is the natural logarithm function (i.e. logarithm base :math:`e=2.718...`)

* :math:`\pi = 3.14159...`

* :math:`|*|` is the determinant of :math:`*`

* :math:`\Sigma_i` is the *filtered* model-implied manifest covariance matrix

* :math:`X_i` is the *filtered* row *i* of the data set

* :math:`M_i` is the *filtered* model-implied manifest means row vector (:math:`1 \times p` matrix)

* :math:`\Sigma_i^{-1}` is the inverse of :math:`\Sigma_i`

* :math:`(*)^{\sf T}` is the transpose of :math:`*`

There are several important things to note about Equation (1).

First, the model-implied means vector and the model-implied covariance matrix are for the the manifest variables only.  Although your structural equation model may involve both latent and manifest variables, the latent variables are only present to explain the means and covariances of the observed variables in a meaningful and parsimonious way.  The free parameters of your model are adjusted to make the model-implied means vector and the model-implied covariance matrix as close as possible to the observed means vector and the observed covariance matrix.

Second, there are several references to filtered vectors and matrices.  Filtering is how FIML handles missing data.

1.  Filtering
2.  Manifest variables only
3.  Inverse of a non-positive definite matrix
4.  Quadratic product

The minus two log likelihood of the entire data set is the sum of the minus two log likelihoods of the rows.

.. math::
    :nowrap:
    
    \begin{eqnarray*}
    \mathcal{L} = 
    \sum_{i=1}^N \mathcal{L}_i
    \end{eqnarray*}

where there are :math:`N` rows in the data.


Row Objective Example
---------------------

We will now implement FIML using a row-wise objective function.  The ``mxRowObjective()`` function evaluates an ``mxAlgebra`` for each row of a data set.  It then stores the results of this row-wise evaluation in an ``mxAlgebra`` which is by default called "rowResults".  Finally, the row results must be collapsed into a single number.  Another ``mxAlgebra`` called the "reduceAlgebra" takes the row results and reduces them to a single number which is then minimized.

Data
^^^^

For this example we will simulate our own data.  We will use the ``mvrnorm()`` function which lives is the ``MASS`` package.  The ``mvrnorm()`` function generates a multivariate random normal sample with a given vector of means and a given covariance matrix.  The following code generates the data.

.. code-block:: r

    require(MASS)
    set.seed(200)
    rs <- .5
    xy <- mvrnorm (1000, c(0,0), matrix(c(1, rs, rs, 1), nrow=2, ncol=2))

The data have 2 variables with 1000 rows.  The true means are 0.  Each variable has a true variance of 1.0, and a covariance of 0.5.

Some further data processing will prove helpful.  First, we recast the generated data as a ``data.frame`` object in R.  Second, we tell R that what we want the variables names to be.  Finally, we look at a summary of the data set and the observed covariance matrix which differs slightly from the covariance matrix used to generate the data.

.. code-block:: r

    testData <- as.data.frame(xy)
    testVars <- c('X','Y')
    names(testData) <- testVars
    summary(testData)
    cov(testData)

Now the data has been generated and we can specify the saturated model.

Model Specification
^^^^^^^^^^^^^^^^^^^

.. code-block:: r

    bivCorModel <- mxModel(name="FIML BivCor",
        mxData(
            observed=testData, 
            type="raw",
        ),
        mxMatrix(
            type="Full", 
            nrow=1, 
            ncol=2, 
            free=TRUE, 
            values=c(0,0), 
            name="expMean"
        ), 
        mxMatrix(
            type="Lower", 
            nrow=2, 
            ncol=2, 
            free=TRUE,
            values=.2, 
            name="Chol"
        ), 
        mxAlgebra(
            expression=Chol %*% t(Chol), 
            name="expCov", 
        ),
        mxMatrix("Full", 1, 1, values = log(2*pi), name = "log2pi"),
        mxAlgebra(
            expression=omxSelectRowsAndCols(expCov, existenceVector),
            name="filteredExpCov",
        ),
        mxAlgebra(
            expression=omxSelectCols(expMean, existenceVector),
            name="filteredExpMean",
        ),
        mxAlgebra(
            expression=log2pi %*% 2 + log(det(filteredExpCov)),
            name ="firstHalfCalc",
        ),
        mxAlgebra(
            expression=(filteredDataRow - filteredExpMean) %&% solve(filteredExpCov),
            name = "secondHalfCalc",
        ),
        mxAlgebra(
            expression=(firstHalfCalc + secondHalfCalc),
            name="rowAlgebra",
        ),
        mxAlgebra(
            expression=sum(rowResults),
            name = "reduceAlgebra",
        ),
        mxRowObjective(
            rowAlgebra='rowAlgebra',
            reduceAlgebra='reduceAlgebra',
            dimnames=c('X','Y'),
        )
    )


Row Objective Specification
^^^^^^^^^^^^^^^^^^^^^^^^^^^

Model Fitting
^^^^^^^^^^^^^

